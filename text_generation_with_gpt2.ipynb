{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0570dea7",
   "metadata": {},
   "source": [
    "# Text Generation with GPT-2\n",

   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f51a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install transformers\n",
    "!pip install torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a5dd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598774b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb68eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_text(prompt, max_length=200):\n",
    "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(inputs, max_length=max_length, do_sample=True, top_k=50, top_p=0.95, temperature=0.8)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4862625",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Try it out!\n",
    "prompt = \"The future of artificial intelligence in education is\"\n",
    "generated_text = generate_text(prompt)\n",
    "print(generated_text)\n"
   ]
  },
